{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ec8d6a-4218-49b9-a549-0977cec82967",
   "metadata": {
    "id": "MVpsYfWg3z0B"
   },
   "source": [
    "# PW1 - Handwritten character recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d682452d-e56e-4de8-a420-4418d63790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your name here (e.g. \"Edmond Dantès\") so I can grade your work\n",
    "your_name = \"Marc Deroo\"\n",
    "assert your_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8538cf7-81e0-481a-8059-be38b611aafb",
   "metadata": {
    "id": "8CcAqNjJ3z0F"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, sys, os, torch, torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c864b86e-6e6b-4d8a-82c8-6822072a676f",
   "metadata": {
    "id": "3Wxb9pdV3z0F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa038da6-b812-4053-9b72-8ff97ceb3b9b",
   "metadata": {
    "id": "1Sjq8zzf3z0G"
   },
   "source": [
    "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "137adce6-13cc-4ccc-aaf3-42230e322a9b",
   "metadata": {
    "id": "L9CF0H4O3z0G"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce850e9-ef4e-4323-af2d-be6b94e98994",
   "metadata": {
    "id": "65e20f5e"
   },
   "source": [
    "# Part A - Linear, MLP, and CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff4bd-8b1d-4531-89d8-64ce4e2b6357",
   "metadata": {
    "id": "KSAiV2ov3z0H"
   },
   "source": [
    "## Handwritten digit recognition dataset\n",
    "\n",
    "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429898a-0f57-4cdf-9aa6-7b1121ee4e53",
   "metadata": {},
   "source": [
    "Load the dataset (train and test splits) using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59e1c523-4b78-492a-b103-2861af8c3d89",
   "metadata": {
    "id": "Zu3hU4dQ3z0H"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "root_dir = './data/MNIST/'\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fbaba-b01f-46d0-a1d7-47c59faaf042",
   "metadata": {},
   "source": [
    "How many examples in each split? \n",
    "\n",
    "Plot the first image and label of the training set using `matplotlib`\n",
    "\n",
    "What is the input dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "083f07f4-e129-4e9b-b26e-a32fd4bdb99d",
   "metadata": {
    "id": "9fgMls5P3z0I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc2fbd26-b017-435a-822e-ad382eabd8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4e268ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380c03-1427-4dea-974e-5a38621ea6c1",
   "metadata": {
    "id": "Guv5_hY63z0L"
   },
   "source": [
    "# A.1 - Linear features\n",
    "\n",
    "We start with a very simple model, linear with respect to pixel values.\n",
    "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
    "\n",
    "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
    "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
    "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8e5d-7d84-4a59-aa5d-e942ffa22aa8",
   "metadata": {},
   "source": [
    "Again, use matplotlib to visualize an example of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac111d5c-dfa2-44e2-9a57-f2f4c2caff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def preprocess(x):\n",
    "    x = F.avg_pool2d(x, kernel_size=4)  \n",
    "    return x.view(x.size(0), -1)        \n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(49, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7dadb382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img, sample_label = train_dataset[0]\n",
    "downsampled_img = F.avg_pool2d(sample_img.unsqueeze(0), kernel_size=4).squeeze()\n",
    "\n",
    "plt.imshow(downsampled_img, cmap='gray')\n",
    "plt.title(f\"Downsampled Image (7x7), Label: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becae4-e27f-43ed-a1c5-ced8c16f4cac",
   "metadata": {
    "id": "qeWZ7DeNMG20"
   },
   "source": [
    "## A.2 - Loss and optimizer\n",
    "Create a cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a85b789e",
   "metadata": {
    "id": "a85b789e"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aec31b-3d2b-4b29-ad85-e88a6e25660a",
   "metadata": {
    "id": "ZCnlsh9iMhx_"
   },
   "source": [
    "## A.3 - Training and testing loops\n",
    "Finally, create the functions `train(model, epoch, preprocess, optimizer)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "41ac2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e5485-b676-4f73-bedc-d35c5fcfd394",
   "metadata": {
    "id": "iMXijrch3z0L"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data = preprocess(data)  \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = output.argmax(dim=1)\n",
    "        correct += (preds == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "    train_accuracy = 100. * correct / total\n",
    "    print(f\"[Epoch {epoch}] Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "\n",
    "def test(model, preprocess):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = preprocess(data)  \n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1)\n",
    "            correct += (preds == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359382-2580-44ae-bcdb-3f18cf1f4c61",
   "metadata": {
    "id": "_t4SiXk33z0L"
   },
   "source": [
    "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f12bf85-45c6-41d9-87f3-0601bc4b6339",
   "metadata": {
    "id": "nBmfvtl6UbUe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Accuracy: 82.49%\n",
      "Test Accuracy: 87.06%\n",
      "[Epoch 2] Train Accuracy: 86.30%\n",
      "Test Accuracy: 87.68%\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, _ = train(model, epoch, preprocess, optimizer)\n",
    "    test(model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bb4e-7178-4340-9247-f69591e86dcf",
   "metadata": {
    "id": "RrwYAMMBEUPN"
   },
   "source": [
    "## A.4 - Multi-layer perceptron (MLP)\n",
    "\n",
    "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb6479-d475-4f0e-b0f7-fdd107d9e835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8353cd9",
    "outputId": "c7f5eeaf-0638-45c3-842e-4372d21ff712"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=49, width=100, depth=3, output_dim=10):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d44d583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Accuracy: 82.92%\n",
      "Test Accuracy: 93.17%\n",
      "[Epoch 2] Train Accuracy: 92.96%\n",
      "Test Accuracy: 92.97%\n"
     ]
    }
   ],
   "source": [
    "model = MLP(input_dim=49, width=100, depth=3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, _ = train(model, epoch, preprocess, optimizer)\n",
    "    test(model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5a11-93e4-47ab-81f1-e4ee3cae45c9",
   "metadata": {
    "id": "v1czyC9R3z0R"
   },
   "source": [
    "# A.5 - Deep convolutional model\n",
    "\n",
    "Write a convolutional model, with learned features.\n",
    "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e318-5521-4bf8-b011-bdb95ed0d8b0",
   "metadata": {},
   "source": [
    "\n",
    "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
    "\n",
    "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c87b30-36d7-4567-b009-a41413afac5b",
   "metadata": {
    "id": "l4QOi_oe3z0R"
   },
   "outputs": [],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)       \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc = nn.Linear(8 * 13 * 13, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)           \n",
    "        x = F.relu(x)              \n",
    "        x = self.pool(x)           \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc(x)             \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09c9911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Accuracy: 89.25%\n",
      "Test Accuracy: 93.34%\n",
      "[Epoch 2] Train Accuracy: 94.34%\n",
      "Test Accuracy: 96.07%\n",
      "[Epoch 3] Train Accuracy: 96.28%\n",
      "Test Accuracy: 96.73%\n",
      "[Epoch 4] Train Accuracy: 97.06%\n",
      "Test Accuracy: 97.05%\n",
      "[Epoch 5] Train Accuracy: 97.58%\n",
      "Test Accuracy: 97.50%\n",
      "[Epoch 6] Train Accuracy: 97.90%\n",
      "Test Accuracy: 97.93%\n",
      "[Epoch 7] Train Accuracy: 98.17%\n",
      "Test Accuracy: 97.94%\n",
      "[Epoch 8] Train Accuracy: 98.33%\n",
      "Test Accuracy: 98.05%\n",
      "[Epoch 9] Train Accuracy: 98.46%\n",
      "Test Accuracy: 98.21%\n",
      "[Epoch 10] Train Accuracy: 98.58%\n",
      "Test Accuracy: 98.17%\n"
     ]
    }
   ],
   "source": [
    "model = ConvModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, _ = train(model, epoch, lambda x: x, optimizer) \n",
    "    test(model, lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0313eed-03ad-461d-9ddb-bb690c631149",
   "metadata": {
    "id": "pbQ1LUqf3z0R"
   },
   "source": [
    "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
    "\n",
    "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
    "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815b111",
   "metadata": {},
   "source": [
    "**Réponse :** En ajoutant des couches linéaires supplémentaires avec h=100, on observe une légère amélioration de la précision sur le jeu de test, et une grande amélioration sur les données d’entraînement. Ce modèle semble mieux, mais il faut surveiller l’overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "792791e1-0514-4749-a3fb-d27eb10a1bd2",
   "metadata": {
    "id": "YM-OhC123z0R"
   },
   "outputs": [],
   "source": [
    "class ConvDeepModel(torch.nn.Module):\n",
    "    def __init__(self, h=100):\n",
    "        super(ConvDeepModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        flatten_dim = 8 * 13 * 13\n",
    "\n",
    "        self.fc1 = nn.Linear(flatten_dim, h)\n",
    "        self.fc2 = nn.Linear(h, h)\n",
    "        self.fc3 = nn.Linear(h, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)           \n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)           \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))    \n",
    "        x = F.relu(self.fc2(x))    \n",
    "        x = self.fc3(x)            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "59e8aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Accuracy: 89.84%\n",
      "Test Accuracy: 96.33%\n",
      "[Epoch 2] Train Accuracy: 96.92%\n",
      "Test Accuracy: 97.38%\n",
      "[Epoch 3] Train Accuracy: 97.88%\n",
      "Test Accuracy: 97.79%\n",
      "[Epoch 4] Train Accuracy: 98.43%\n",
      "Test Accuracy: 98.21%\n",
      "[Epoch 5] Train Accuracy: 98.69%\n",
      "Test Accuracy: 98.36%\n",
      "[Epoch 6] Train Accuracy: 98.93%\n",
      "Test Accuracy: 98.30%\n",
      "[Epoch 7] Train Accuracy: 99.11%\n",
      "Test Accuracy: 98.60%\n",
      "[Epoch 8] Train Accuracy: 99.28%\n",
      "Test Accuracy: 98.27%\n",
      "[Epoch 9] Train Accuracy: 99.42%\n",
      "Test Accuracy: 98.44%\n",
      "[Epoch 10] Train Accuracy: 99.55%\n",
      "Test Accuracy: 98.45%\n"
     ]
    }
   ],
   "source": [
    "model = ConvDeepModel(h=100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, _ = train(model, epoch, lambda x: x, optimizer)\n",
    "    test(model, lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd763b-b36a-461c-ad34-f472e62ce46d",
   "metadata": {},
   "source": [
    "## A.6 Visualisations of convolutions\n",
    "\n",
    "After training your model, let's see what features it has learned!\n",
    "\n",
    "Plot an image from the test set then plot all 8 feature maps extracted by the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5284c2-4210-4ccc-bf05-5e722bdabf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, dataset):\n",
    "    model.eval()\n",
    "\n",
    "    image, label = dataset[0]\n",
    "    image = image.unsqueeze(0)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = model.conv(image)\n",
    "        x = F.relu(x)  \n",
    "        feature_maps = x.squeeze(0)  \n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Original Image - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(10, 5))\n",
    "    for i in range(8):\n",
    "        ax = axs[i // 4, i % 4]\n",
    "        ax.imshow(feature_maps[i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Feature Map {i+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7b72e641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAERCAYAAABSGLrIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEW1JREFUeJzt3QuQjfUfx/HfxhIWrbvEqk2F0cSm5JJlJVmhSFFZ0W6XbUtJmaZiVEhTKV1V03XLhDKlMiqyipppK9YlsuSSymZXbmHZ5z/f3/zPzjlnzz7n2N1z9vJ9v2YO9vye8zzPec7zeX6356wox3EcA6BGO62ydwBA+BF0QAGCDihA0AEFCDqgAEEHFCDogAIEHVCAoAMKVLugT5s2zURFRZXptW+99ZZ97e+//27CRdYt25BtofKMGzfOxMTEVOg6ExMT7aM6iljQN2zYYG666SbTpk0bU7duXXPmmWeaG2+80T6v0TfffGMvCAsXLqzsXaky2rdvb4YMGWJqorf+X8mU9sjMzAzr9mubCPjoo4/M6NGjTZMmTcyECRPM2WefbWu+N954w57o8+fPN9dcc01I63r44YfNlClTyrQfN998s7nhhhvshQaIpMsvv9y8++67JZ5/9tlnzdq1a01SUlL1Dnpubq4N2DnnnGOysrJM8+bNi8vuuece06dPH1u+bt06u0xpDh8+bBo0aGBq165tH2VRq1Yt+wAiTc5t//P7v//+M3feeafp37+/adWqVfVuuj/11FPmyJEjZt68eT4hF82aNTOvvvqqDfHs2bNL9MM3btxoxowZY2JjY03v3r19yvwP2N13323X17BhQzN06FDzxx9/2OVkebc+uqe5+O2335pLLrnEnH766fYDeeedd3y2kZ+fb+6//37TpUsX2/dr1KiRueqqq+zVuKJ43tuWLVtsN6dx48b2mD3yyCNGvmS4a9cuM2zYMLttOTGefvppn9cfP37cPProoyYhIcG+Vi6MciFdsWJFiW3t27fPXmBlXWeccYZJSUmx7yXQ+MKvv/5qRo4caVtkcnwuvvhi88knn5jKsGrVKnPdddeZdu3a2ZZZ27Ztzb333mvPgUC2bdtmrrzySnsspLs4ffp0eyy9FRUVmTlz5pjOnTvb99eyZUtz2223mYKCgqD7s3PnTnt8yuLTTz81Bw8etF3YcAt70OXNSJjkhCutSSPln332WYky+UDlIjFjxgyTmprqOvAyd+5cM3jwYPPkk0+aevXqmeTk5JD3cevWrfZEvuKKK2x45MIi6/QeP5ATZvHixfai8Mwzz5jJkyebnJwc07dvX7Nnzx5Tka6//np78s2aNctceuml5vHHH7cnouyfjHHIezz33HPthUdaSR4HDhwwr7/+uh0wkmXkwpGXl2dP9F9++aV4OVn31VdfbT744AMb8CeeeML8+eef9t/+5Bj06NHDbNq0yXaZ5PhIaIYPH24+/vhjE2kLFiyw58Qdd9xhP3N5b/L32LFjSyx78uRJM2jQIBtcqUjkAjh16lT78Cahls+zV69e5rnnnjO33HKL7TPLugsLC133R7bbsWPHMr0X2Yacq9dee60JOyeM9u/fL5dOZ9iwYa7LDR061C534MAB+/PUqVPtz6NHjy6xrKfMIzs72/48ceJEn+XGjRtnn5flPd5880373Pbt24ufi4uLs89lZWUVP7d3716nbt26zqRJk4qfO3r0qHPy5Emfbch6ZLnp06f7PCfrk225WbFihV1uwYIFJd5bWlpa8XMnTpxwzjrrLCcqKsqZNWtW8fMFBQVOvXr1nJSUFJ9ljx075rMdWa5ly5bO+PHji59btGiR3c6cOXOKn5P31r9//xL7npSU5HTp0sW+f4+ioiKnZ8+eTocOHZyKJJ9FcnKy6zJHjhwp8dzMmTPt8dmxY0fxc3Jc5L1kZGT47Lesv06dOk5eXp59btWqVXa5zMxMn3UuXbq0xPN9+/a1D2/yc1litG/fPrsfo0aNciIhrDW6NEuENKfdeMqlRvJ2++23B93G0qVL7d/S1/GWkZER8n526tTJp8UhzeXzzz/f1uIe0kw87bTTimsKafpKE16W++mnn0xFuvXWW4v/LWMK0lSW5qYMZHpIc9t/H2XZOnXqFNfa0t04ceKEfb33Psoxi46O9mklyXtLT0/32Q95/fLly82oUaPsZ/nPP//Yh7x3qe1+++0320WKJKkBPaTLJ/vTs2dPe3x+/vnnEsvfddddxf+Wbon8LF2cr776qriFIN0caS153p88pPaXzzdQt8d/9qQsv7tFBqFlPyLRbA/7YJwnwJ7An+oFQUbng9mxY4c9Sf2XlaZtqKS/50+a7959NAmONOteeukls337dht2j6ZNm4a8rbLsj5yI0neUMQj/5yV03t5++23bvJZ+o3ez0/v4yDFr3bq1qV+/vusxky6NnMQyRiCPQPbu3Wu7E4FIt8H7OElwyju3LX1iGYeQMQL/PvS///7r87OcF/4DYOedd5792zNOIxcreV2LFi1KfX/hIM12GfOQcZ5qH3Q5EeWEkhF1N1IuJ4sMDJV29Q6n0kbiva/UMk4gJ/v48ePNY489Zj8kOZEmTpxoLwLh3p9Q9vG9996zYwvSf5Y+p5y88rqZM2fa2Y9T5XlfMhYgNXggbhfU7t2724uKh/SNvQdHT5VcNKTmlZbGgw8+aC644AI7XiCtCnnfZfkcioqK7HEqbR7bfwC5IsjFSgYV09LSbMsqEsI+vSaDV6+99pod1faMnHuTNyxXVxkQKYu4uDj7YUkt26FDB5/aqCJJU6tfv3527t/b/v37S9S0lUX2UWowuW/Be2bCf/BJjpk0SWVQy7tW9z9mntpQTsYBAwac8v5IeLxHw92mT0Mhg58yIyGtFu/Bty+//DLg8nJeSNfmvP/X4kJeL2QAWMTHx9tmvAzERapikUFQuUBHqtkekVF3qVnkAEqQ/ZuZcmWWfricbLJcWXhqGmlSe5OR2IokNaN/X0z6d5Huo7rx1Pre+/nDDz+YNWvW+CznGU2WC7B3KF588UWf5aSmkxF8mQKVUflATXM3Eh65QHge5Q16oPcn/5YuVWleeOEFn2XlZ7lweW5QkfEHaSlIK82fjG/Ihbyip9fef/992z0LVPFV2xpdalm5AsvVS+ag/e+Mk4EPucLJlbUsZNBkxIgRdvpJLiQyFbRy5criK3dZ74sP1DKROViZepHBH6ldpMYq78lbkWQfpTaXuwxlelFaOa+88oodbDx06FDxctK0l3sGJk2aZGtxaQJLn1cuvP7HTMIvJ6R8djJ4J+/377//theP3bt3V+h9BEL2R6YT/XXt2tUMHDjQnifSlZALrHT1Fi1aVOp8t4xryMBjSkqKnab84osv7DTuQw89VNwkl+lRqYSkeyNTkLINuRBI310u5HIRkanX0kjLQs63UAfk1q9fb7uqMlVZUedmSCIytu84zrp16+x0WevWrZ3o6GinVatW9uecnJwSy3qmmTxTIIHKvB0+fNhJT093mjRp4sTExDjDhw93Nm/ebJfznpIqbXot0JSO/1SKTC/JdJvsv0xr9erVy1mzZk2J5Spies3/fctUUYMGDQLuY+fOnX2mj2bMmGHfk0z7de3a1VmyZIl9vTznTbYxZswYp2HDhk7jxo3tdOR3331ntz9//nyfZXNzc52xY8faz0w+uzZt2jhDhgxxFi5c6FQkz1RnoMeECRPsMhs3bnQGDBhgP+dmzZo5qampztq1a0scc88xk30fOHCgU79+fTvNKMfYf5pUzJs3z0lISLCfrRwTmVJ84IEHnD179lTo9NqUKVPs8pKHSIqSP0wNJFdnqQVkgCqSfaHqTG4IktaAjKdIsxs1R7X7mmoggW5/lKa8jIrLnXcIfsyknyrjGtIc7tatW6XtF6rxt9fCTW5vzM7OtqPi8oUX6YvJQ6Yv5F5olCQ3FEnYL7vsMnPs2DHbt1+9erWdRozU6DMiyKkBli1bZvvMsbGxtg8ZHx/vTJs2zSksLKzsXauy5NbObt26OY0aNbK3Ynbq1MmZO3duZe8WwqTG9tEB1LA+OgB3BB1QgKADCoQ86h7Ru3gAhCyUYTZqdEABgg4oQNABBQg6oABBBxQg6IACBB1QgKADChB0QAGCDihA0AEFCDqgAEEHFCDogAIEHVCAoAMKEHRAAYIOKEDQAQUIOqAAQQcUIOiAAgQdUICgAwoQdEABgg4oQNABBQg6oABBBxQg6IACBB1QgKADChB0QAGCDihA0AEFCDqgAEEHFCDogAIEHVCAoAMKEHRAAYIOKEDQAQUIOqAAQQcUIOiAAgQdUICgAwoQdEABgg4oQNABBQg6oABBBxQg6IACBB1QgKADChB0QIHaRpGRI0cGXSY1NdW1fM+ePa7lR48edS3PzMwMug9//fWXa/nWrVuDrgPwRo0OKEDQAQUIOqAAQQcUIOiAAgQdUICgAwpEOY7jhLRgVJSp7rZt2xZ0mfbt25vKdvDgQdfyDRs2RGxfqrLdu3e7ls+ePdu1/McffzQ1QSgRpkYHFCDogAIEHVCAoAMKEHRAAYIOKEDQAQVUfR892HfNxYUXXuhavmnTJtfyjh07upZ369Yt6D4kJia6lvfo0cO1fNeuXa7lbdu2NeF24sQJ1/K8vLyg62jdunW59mHnzp0q5tFDQY0OKEDQAQUIOqAAQQcUIOiAAgQdUICgAwqo+j56dREbG+taftFFF7mWZ2dnu5Z3797dhFuw32+/ZcuWoOsIds9CkyZNXMvT09Ndy19++WVTE/B9dAAWQQcUIOiAAgQdUICgAwoQdEABgg4oQNABBbhhBpVixIgRQZf58MMPXcvXr1/vWt6vXz/X8vz8fFMTcMMMAIugAwoQdEABgg4oQNABBQg6oABBBxRgHh1h0aJFC9fynJyccq9j5MiRruWLFi0yGjjMowMQBB1QgKADChB0QAGCDihA0AEFCDqgQO3K3gHUTMH+84TmzZsHXUdBQYFr+ebNm095v7SiRgcUIOiAAgQdUICgAwoQdEABgg4oQNABBfg+OsqkV69eruXLly93LY+Ojg66jcTERNfyrKysoOvQwOH76AAEQQcUIOiAAgQdUICgAwoQdEABgg4oQNABBfjFEyiTwYMHl+uGmK+//jroNtasWXPK+4XAqNEBBQg6oABBBxQg6IACBB1QgKADChB0QAHm0RFQvXr1XMsHDRrkWn78+HHX8qlTpwbdh8LCwqDLIDTU6IACBB1QgKADChB0QAGCDihA0AEFCDqgAPPoCGjy5Mmu5V27dnUtX7p0qWv56tWry7RfKBtqdEABgg4oQNABBQg6oABBBxQg6IACBB1QIMoJ5X9RlwWjosK/N4iI5OTkoMssXrzYtfzw4cPl+r76999/H3QfEJpQIkyNDihA0AEFCDqgAEEHFCDogAIEHVCAoAMKEHRAAX7xRA3UtGlT1/Lnn38+6Dpq1arlWv7555+7lnNDTNVCjQ4oQNABBQg6oABBBxQg6IACBB1QgKADCvCLJ6qhYHPcweawExISgm4jNze3XL9YItjrUXH4xRMALIIOKEDQAQUIOqAAQQcUIOiAAgQdUIDvo1dD8fHx5Z4nD+a+++5zLWeevHqhRgcUIOiAAgQdUICgAwoQdEABgg4oQNABBZhHr4Li4uJcy5ctW1au9U+ePDnoMkuWLCnXNlC1UKMDChB0QAGCDihA0AEFCDqgAEEHFCDogAIEHVCAG2aqoLS0NNfydu3alWv9K1euDLpMiP+vB6oJanRAAYIOKEDQAQUIOqAAQQcUIOiAAgQdUIB59Ajr3bt30GUyMjIisi/QgxodUICgAwoQdEABgg4oQNABBQg6oABBBxRgHj3C+vTpE3SZmJiYcm0jNzfXtfzQoUPlWj+qH2p0QAGCDihA0AEFCDqgAEEHFCDogAIEHVCAefRqaO3ata7lSUlJruX5+fkVvEeo6qjRAQUIOqAAQQcUIOiAAgQdUICgAwoQdEABgg4oEOWE+D/eR0VFhX9vAJyyUCJMjQ4oQNABBQg6oABBBxQg6IACBB1QgKADCoT8iydCnG4HUAVRowMKEHRAAYIOKEDQAQUIOqAAQQcUIOiAAgQdUICgA6bm+x9TAtxAPtTpTwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8gAAAHtCAYAAADFrFeuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMa1JREFUeJzt3QmYXFWZMODbS9bOSvaEJCQhASEKAWQJgQGUXRDQoKBIJCCMIOA/4I8gIAoMAsOiLP4KgoAswyYDDsNmFJAtiBB2AiSBELKyZV+663/OvXamu9M51Z100lVd7/s8le7Ud+vWqer6quo799xzynK5XC4BAACAElfe2g0AAACAQqBABgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAACAAhkAAAAyCmQAAAAolQL5xhtvTMrKyhq9nHHGGRvkPp966qnkpz/9afLJJ58khfx8PPnkk2vEc7lcMnjw4DT+la98pVXaeO211ybjx49PhgwZkrZjwoQJrdIOCpe8Lq68fv/995Pzzjsv2XHHHZOePXsmvXv3TvbYY4/k0Ucf3ehtoXDJ6+LK66VLlyYTJ05MRo8enXTv3j3p0qVLss022yRXXnllsnLlyo3eHgqTvC6uvG4otLG2vfPnz09KQWVSQn72s58lw4YNq3ddeFPfUIkZvgyGwq5Hjx5JIerYsWNy6623JuPGjat3/V//+tdk5syZSYcOHVqtbb/4xS+ShQsXpl+mP/zww1ZrB4VPXhdHXt93331pXh9yyCHJ0UcfnaxatSq56aabkr333jv53e9+l3z3u99tlXZRmOR1ceR1KJBfffXV5IADDkg222yzpLy8PH0+f/jDHybPPvts2maoJa+LI6/rqqmpSX7wgx8kVVVVyeLFi5NSUVIF8v7775/ssMMOSTELL87wIm0J4QPtzjvvTH75y18mlZX/+1IIybr99tu3ai9ReHOoPXoceqRhbeR1ceT1nnvumbz33nvpkeNaJ5xwQrLtttsm55xzjgKZeuR1ceT1JptskjzzzDP1rgt5HY4mX3XVVclll12W9O/fv1XaRuGR18WR13X95je/SUeAHXvssenIkFJREkOsm+rBBx9Mdtttt/SF37Vr1+TAAw9Me0brmjJlStobNXz48LTnJ7zxH3PMMcmCBQtWbxOGdJx++unp76GnrHZYwvTp09NL+D0Mr2goXB9uW3c/4brXXnstOfLII9NhiXV7mW655ZY0gTp16pR+SH3zm99MX8RNdcQRR6TtfuSRR1Zft2LFiuSuu+5K768xl156aTJ27NikV69e6f2G+w/bN/ZYTjrppOQPf/hDssUWW6TPVdj28ccfb1Lbhg4dmu4D1pe8Loy83nrrresVx0HoHQ9fEEJPeRgxAk0lrwsjr9cmHE0OCnF4K4VLXhdWXn/00UfJT37yk/TIf6Eehd9QSqpA/vTTT9PemLqXWjfffHOaiOFoZRgGePbZZ6cJERIhJFOt8CJ+991306Mdv/rVr9JkuP3229MveeGcgeCwww5LX/TB5Zdfnu47XPr06bNO7Q7n4i5ZsiS58MILk+OOOy697oILLki+853vJCNHjkx7aE899dTkscceS3bfffcmfyCFD7Bddtklue222+q9OYXnKTyuxoTeozFjxqTJEtoTerxC+/70pz81ehQ4tOvb3/52un14E9hvv/2SV155ZZ2eB2iMvC7uvJ49e3bSuXPn9AK15HVx5XX4Uh/+RqE4uPfee9Mv8aGje/PNN2/S7SkN8rq48vrss89OOyCOP/74pOTkSsANN9wQMqbRS7Bw4cJcjx49cscdd1y9282ePTvXvXv3etcvWbJkjf3fdttt6b4ef/zx1dddcskl6XXTpk2rt234f7g+tKmhcP255567+v/h93DdEUccUW+76dOn5yoqKnIXXHBBvetffvnlXGVl5RrXr+35mDx5cu6qq67Kde3adfXjGj9+fG7PPfdMfx86dGjuwAMPrHfbho9/xYoVudGjR+f22muvNR5LuDz//POrr5sxY0auY8eOuUMPPTTXHFVVVbmjjz66Wbeh7ZPXxZ3XwdSpU9PbHnXUUc2+LW2TvC7OvK59XmsvO+ywQ27KlClNui1tn7wuvrx+6aWX0sf40EMP1Xsu5s2blysFJXUE+eqrr057nupegvAz9PaE3qa6vVoVFRXJTjvtlEyaNGn1PsJwhlrLli1Lt9t5553T/7/wwgsbpN3hfJ667rnnnvSk+cMPP7xee0MvT+jJqtvefMI+wiQbDzzwQDrEMfxc27COho//448/Tnu5wnCYxh576BULwzlqhXOKv/rVryYPPfRQUl1d3eQ2Qoy8Ls68Dr3xodc73PdFF13U5NtRGuR1ceV1mGMg/G3C+ZThOWjXrl1JTehD08jr4snrk08+OT1nfJ999klKUUlN0hVmRG5scoCpU6emP/faa69Gb9etW7d64/HDrHhhOMfcuXPrbRdepBtCwxn/QntD51BIwsaED6amCsNNvvzlL6cTAoQvrCFhvv71r691+5C4559/fvLiiy8my5cvX319Y+cLN9a+UaNGpfczb948E3fQIuR18eV1aE8YPhaGz4XhZAMHDmzyY6M0yOviyut+/fqllyC0KQz9DDPUh8fvs55a8ro48vqOO+5IZwEv5VMiS6pAXpvQCxSE8xMae7HUnVku9PSEF004+T/MvhrOlQi3D2P6a/cTs7aJp2I9OXV7i2rbG/YTvliG3rWGmjvrc+ipCudUhHMBQ2/R2k7Ef+KJJ5KDDz44Pb/immuuSQYMGJC+Cdxwww2WcqDgyOvCzevQrvAhHyYPWdsXImiMvC7cvK4rfME/66yz0uXdSvL8RZpFXhdWXp9++unpCK/27duvPv+79rzqMM9AmHOgrXdsK5CTJBkxYkT6s2/fvmkvztqEoQzhBPzQcxWWJWnY89WUBAwz4AUNT+CfMWNGs9obeq5Cj1boCVpfhx56aPoBFpZqCL1Ga3P33Xens+CFoRl112YLidmYxp6Xt956K52MZ10nSoCmkteFmdfhgzfs+4orrlg9iQo0lbwuzLxuKAwZ3ZBH9Ghb5HVh5fX777+fFtyNFd3bbbddss0226RHsNuykjoHeW323XffdPhGGBK0cuXKNeJhGEJQ20tUO0terfBFr6HaNdIaJmC4n7DUScNp1kNPUFOF2flCW8IbRMO2hP/Xneq+KUJP17XXXptOZ3/QQQetdbtwn+ENp24vW+hZ+uMf/9jo9k8//XS9cyJCwoXe5HA+Q2M9btCS5HXh5fUll1ySzm575plnJqecckqzHg8E8rqw8jqcd9nwcQXXXXdd+rPY17xl45DXhZXX99577xqXb3zjG2nspptuSmcGb+scQf5nsoQX5lFHHZX2jIRz40LPynvvvZdOm77rrrumC96H7cKwhosvvjhN4EGDBiUPP/xwMm3atDX2WXtSfBhiFPYXhkCEF31I2LDYdpiUJvwMHx4hSUOPTnN6rsL5Bz/+8Y/TxDjkkEPS9eJCO8KL+Hvf+15y2mmnNes5OProo/NuE6bfD1PZh2EsYThIOPcjTLgQlnEI69I1NHr06PRNL5zoH3q6at98whtKPvfff3/y0ksvpb+H5zrsPzzmIAwv+cIXvtCsx0fpkdeFldfhMfzoRz9Kz4n63Oc+l64fWVc4X7H2HEZYG3ldWHkd8vjXv/51+rjCurRhkqFwdCtMuhSeQ6dQ0BTyurDy+pBDDlnjutojxmEIeOhgaPNyJaDudOoxkyZNyu27777plPJhGvQRI0bkJkyYUG+K9JkzZ6bTo4fp6MN2YTr2WbNmrTE1fPDzn/88N2jQoFx5eXm9qebDFO0TJ05Mbx+mdj/88MNzc+fOXev08mubUv3uu+/OjRs3Ll0GKVy23HLL3Iknnph78803W+T5aGx6+euvvz43cuTIXIcOHdL7C/uqbWdd4f+hLbfccsvq7ceMGZM+x00RlnVa25IAjU3NT+mR18WV17X7W9ulqe8NtG3yurjyOrQrPK9DhgxJbxce23bbbZe77LLLcitXrsx7e0qDvC6+7+ENldoyT2Xhn9Yu0ml7whCQE088Me3xA9oGeQ1tj7yGtkderx/nIAMAAIACGQAAADIKZAAAAAhD1J2DDAAAAI4gAwAAQEqBDAAAAApkAAAAyFQmTbR3+fimbgpEPFJzZ1Io5DW0DHkNbU8h5XUgt2Hj5LYjyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAASJKksrUbANCayjp0iMZzy5dvtLZAW1DZv1/ebeYcNDwazx28IBrfqf970fhfZmwejZc/3y0aH/SXRdF4xdSZ0Xj1go+icShZZWXx8HZbReMrenaMxjvMXRyN17z8ZjSe5HLxOCXBEWQAAABQIAMAAEBGgQwAAAAKZAAAAMgokAEAAECBDAAAABkFMgAAAFgHGSh07507NhrvGF8uNel/3QvReM2yZevSLJqhcrMh0fiq6fE1bSkuK0YOzLtN2VfjifvYtr+Pxh9YvGk0PmH7J6Lxmu3ixwd2PrkiGp+yIv6+saSmXVLsPqnpHI3/+oM9ovF37h8RjQ+5fUbeNqya+UHebSgu5V26ROOLhsbj8z8fz81ceYdovOLAXaLxbtNrovHub8fXWS4G1Z3j5d9nQ+JrTXeduTwar5gU/95VDBxBBgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAACAdZCB1lTRp0/ebZYNWRHfoKx9NLx899HR+NLe8bfBsviSiEnVzPh6qEv7xddk7P7C7Gh8yRZ98/d0rog3MldZFo2v6BZfV7LblPnReE1VfM3E3LI8f0PalIpnXs27Te9vxNcJPnxxfK3S/Aav160/+m78/j/dZ0k0fsCo+HPQrqw6bxs265gn73LxYxwfraqKxj9eFV/nuEtFfK3Tbu2XRuN5dp/U9O6e5GUd5DanZuHCaLzzPc9G40PuWb/7z+2yTTS+eHCnPDvIRcNlK/Pn9qpuHdfr8GV1u/gG7T+J5251hzxrSX8z/t7Tresn0fjCldsm+ZQ/+WJSyBxBBgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAABAqa2DPOu0sdH4os1XReMVi+P9CV2nxeMD7343Gl81NM96p89MSQp93drqefPWa/+fHBVfe7LHzU+v1/4pLE15vYyauH6vqby+vH00/OmI+DrLiwbFF/tcuHV8DeDuf4uvozxnh/h6sUHnD+PrMubyvNNXd4ivk1x11zvR+LR/j+dtxeaLovEh46Nhikxu5YoW2aY1bXJD/LNmkxvit3+9BdowJemVbFjx7zxJEl8rNUk+i0aHJE9F43mWmIcNouzpl6LxLnm+ZsY/bfPHW+LoZPl6tiHft4oF3xkTjT835s5ofMcR/5rnHpKk55NJQXMEGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAApbYO8sBL42vybWhzJsbXCl04LH77Fcd8MRqv+DT/n7O6e551D2vi66EOeiQe7/rg4mh8xv/ZNhq/eeIV0fhZrx8TjeeefyUah4baPfr3aLz3o+u3/wHruRLp4PPnJIXuraOvjca3fPKojdYWAGDd5T5pH43/cXGXaLzH20uTYucIMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAASm0d5NbW6/qn4/Gk+NXkiXeZmYvGD//b8dH4qFdej8bjewfWxduX7RyNnz9/WTQ+9PCXW7hFwPp6+4p4Xvd9Nn77brc907INAgrC6M/PiMZ/+OiR0fiovz2XFDtHkAEAAECBDAAAABkFMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAYB1kNrb5Y+IrFZfN7RCN1yyLr7cKNF9Zu/bR+ODRs6Px+y/ZMxrvkcTXgAear2Lk8Gj8naP7ReNbbBNf67T61Fnr1C6gsC3+2k7R+IkDb47GL7v4W0lb5wgyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAACgQAYAAICMAhkAAACsg0xLm/3DsdF45eL4OsjDzrReKmxsb177hWj8tE0fisb/6+ZeLdwioKJH92h87u7xdY7HfvmVaHzGOVtE4+0S6yBDW9TtpPej8VOeODIaH/XfzydtnSPIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAACAAhkAAAAyCmQAAACwDjItrXq3T6Px3FvdNlpbgEzFFptH43uNfiMav++4L0XjZcmL69QuIKJPfH3xhcPjN//rc1tF4yMffnZdWgUUuM+O3DkaL18+Nxrf4ppl0Xgul0vaOkeQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAACgQAYAAIBM5T9/QpNMv2CXaHzF3OpofNQZT7dwi4B8ZnytbzQ+IJkdjZf97cUWbhGQz6q+3aLx6o65aHzkyc+2cIuAYvCNs/4nGr/23v2j8S7P+67uCDIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAAKyDTHOVj1oUjfe/t2qjtQVomv2+9kw0/uSVO0XjPRJrIkJLqhg5PO827+7bKRqv3mRFC7YIKBZzTh4bjb+66KVofMSNs6Px6nVqVdviCDIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAAKyDTEPL9/9iNF45uV003u3Wp1q4RUA+7981Ohr/bO7SaLzHTdY5hpZU0adPNP7hvv3z7uPrBz8RjT928a7NbhdQ/A6d+Jdo/PZ79ojGh7ztu3o+jiADAACAAhkAAAAyCmQAAABQIAMAAEBGgQwAAAAKZAAAAMgokAEAAMA6yDQ049B4fNP/qd5YTQGSJJl24S55txnac2Y03u77HaJxWQ3NVF4RDS/ZYbNovPNXZue9i3vf+UI0vumtz+TdB1B83j97bDT+6sI3o/HhN8+KxletU6tKiyPIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAACAAhkAAAAyCmQAAACwDnLpefuKnaPxjrPifSad73mqhVsEpW3JYTtF4wN3+DDvPmY8u2k0PuzNp5vdLmDtasZ+Phr/cMLyaPyHQ57Nex/3btWn2e0Cit8+hzwXjU+6acdovP+7vquvL0eQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAABgHeS2ZdH4+HqqQU33ldH40D+siMZzzW4VEDPs9Nej8SffHJl3HyPPtM4xtKTyjh2j8YWD4vFtBk2Nxv/4rT2a0IpXm7ANUGzevnznaPyt56uj8c/d8kY0Hr81TeEIMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAArINcXCo3HRSNf/yNxXn30fe/ukbjucl/b3a7gLVbcNwu0fgVA/4jGj/tsM5572NVs1sFpa2sXftofNEB20Tj7SfOjsb/8bdR0fjwf1i7HNqiT46Kf+an+iyLhre4Mv6pXr3go+Y2i2ZyBBkAAAAUyAAAAJBRIAMAAIACGQAAADIKZAAAAFAgAwAAQEaBDAAAANZBLi5v/+uQaLxn53l599H9pldasEVAZf9+0fiSfRdG49++8N+i8d4fWi8VWlr5sMHR+Jwvxo8ffKf/G9H4E/93+jq1CyjuNdS3/cGLeffx999sG43nJvvcb22OIAMAAIACGQAAADIKZAAAAFAgAwAAQEaBDAAAAApkAAAAyCiQAQAAQIEMAAAAmcp//qQIHPvVh6PxOy/dpwl7ebvF2gMkyWs/HRqN97s33g/50efj+++9Lo2CElfRs2c0Pm9c32h8q7HvRuN3XbdXNN4veSoaB4pTj790icbP6Pdfefdx4tNDovHqZreKluYIMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAArINcWJbv/8VofP7KydF47wffyXsf1laD5qnotUl8g1w83G5pfINcUrYOrQJiynp0i8YXDY7n3UtvxNcpHfVL6xxDKfrBgEej8TdX9sq/k7kftVyD2CAcQQYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgHWQC8tfrv9tND7m/O9H433nWJcRWlpZ+/bxeKf46uLDTp8ajXfe5bN1ahcQsSqel12nx9cn3+wXL0fjNevUKKDY/eSdQ6PxDyYPzLuPYfOebsEWsSE4ggwAAAAKZAAAAMgokAEAAECBDAAAABkFMgAAACiQAQAAIKNABgAAAOsgF5Y9jjsuGu/Qw8qLsLHN/ObwaHyTJ+Prqc6ZYJ1j2NhWvT8zGu/5+3jcpy3QmOXXD4jGN3/s7bz7iK/STiFwBBkAAAAUyAAAAJBRIAMAAIACGQAAADIKZAAAAFAgAwAAQEaBDAAAAEmSlOVyufgingAAAFACHEEGAAAABTIAAABkFMgAAACgQAYAAICMAhkAAAAUyAAAAJBRIAMAAIACGQAAADIKZAAAACiVAvnGG29MysrKGr2cccYZG+Q+n3rqqeSnP/1p8sknnySF/Hw8+eSTa8RzuVwyePDgNP6Vr3ylVdq4tr/XRRdd1CrtofDI6+LL62DOnDnJ8ccfnwwaNCjp2LFjstlmmyUTJ05stfZQWOR1ceV17O8VLn/4wx82epsoPPK6uPI6+PTTT5Mf/ehHyciRI5NOnTolQ4cOTT+r33vvvaQUVCYl5Gc/+1kybNiweteNHj16gyXmeeedl0yYMCHp0aNHUojCl9Nbb701GTduXL3r//rXvyYzZ85MOnTokLSmvffeO/nOd75T77oxY8a0WnsoTPK6ePL6/fffT3bdddf09xNOOCEtkmfNmpU899xzrdYmCpO8Lo683n333ZObb755jesvv/zy5KWXXkq+9KUvtUq7KEzyujjyuqamJv0O/tprryXf//73k1GjRiVvv/12cs011yQPPfRQ8vrrryddu3ZN2rKSKpD333//ZIcddkiK2eLFi5OqqqoW2dcBBxyQ3Hnnnckvf/nLpLLyf18KIVm33377ZP78+UlrCgn57W9/u1XbQOGT18WT1+HIcWjT5MmTk169erVaOyh88ro48nr48OHppa6lS5emX6r32muvpH///q3SLgqTvC6OvH7mmWfSz+mrrroqOfHEE1dfv8UWWyTHHHNM8uijjyaHHnpo0paVxBDrpnrwwQeT3XbbLX3hh56RAw88MHn11VfrbTNlypS0Nyp8IISen/DmH14sCxYsWL1NGNJx+umnp7+HnrLaYRTTp09PL+H3MLyioXB9uG3d/YTrQg/OkUcemfTs2bNeL9Mtt9ySJlAY+rDJJpsk3/zmN9MjNE11xBFHpO1+5JFHVl+3YsWK5K677krvrzGXXnppMnbs2PTLbbjfcP9h+8Yey0knnZQOrwoJFZ6rsO3jjz+eNEf4oF22bFmzbgN1yevCyOs33ngj/VuE5zDcT8jrlStXNvlxQV3yujDyujH3339/snDhwuRb3/rWOt2e0iWvCyOvP/vss/Rnv3796l0/YMCA9Ge437aupArkMJ4+9MbUvdQKQ4RCInbp0iX5xS9+kZx99tlpQoRECMlUK7yI33333eS73/1u8qtf/SpNhttvvz3tBQrnDASHHXZY+qKvHWYU9h0uffr0Wad2jx8/PlmyZEly4YUXJscdd1x63QUXXJAOPw7nBlx22WXJqaeemjz22GPpcKemnm8Rzv3bZZddkttuu63em1N4nsLjasyVV16ZDnMOw2RCe0KPV2jfn/70pzW2DUNEQrvCUeCwfXgT2G+//ZJXXnmlSe0Lb17hTTIk4lZbbZX2qEFD8ro48jr0ONd+4IZhlyGvwyUcUaj7t4BAXhdHXjcmfCEPuR2eW6hLXhdHXu+www7p9+/wN/jzn/+cfPDBB+m+wjnJX/ziF5Mvf/nLSZuXKwE33HBDyJhGL8HChQtzPXr0yB133HH1bjd79uxc9+7d612/ZMmSNfZ/2223pft6/PHHV193ySWXpNdNmzat3rbh/+H60KaGwvXnnnvu6v+H38N1RxxxRL3tpk+fnquoqMhdcMEF9a5/+eWXc5WVlWtcv7bnY/Lkybmrrroq17Vr19WPa/z48bk999wz/X3o0KG5Aw88sN5tGz7+FStW5EaPHp3ba6+91ngs4fL888+vvm7GjBm5jh075g499NBcPmPHjs1dccUVufvuuy937bXXpvcR9nfNNdfkvS2lQV4XV16ffPLJ6W179eqV22+//XJ33HFH+nx26dIlN2LEiNzixYujt6c0yOviyuuGFixYkGvfvn3u8MMPb9btaNvkdfHl9QMPPJAbMGBAvb/Vvvvum/6tSkFJHUG++uqr056nupcg/Ay9PaG3qW6vVkVFRbLTTjslkyZNWr2PusMKwhDBsN3OO++c/v+FF17YIO0Ok9nUdc8996Qn0B9++OH12huGmYSerLrtzSfsIwxjfuCBB9IhUeHn2oZ1NHz8H3/8cdrLFYbDNPbYQ69YGM5Ra8iQIclXv/rV9AT/6urqaLv+9re/Jaecckpy8MEHp4//73//ezqRw5lnnpm2F2rJ6+LI60WLFqU/w+MJPd2hjaeddlry29/+NnnnnXeMEKEeeV0ced1QGOoZhogaXk1j5HXx5HWfPn3SI9XhSPkf//jHdLj5E088kR65LwUlNUnXjjvu2OjkAFOnTk1/hgklGtOtW7fVv3/00UfprHhhOMfcuXPrbRdepBtCwxn/QntD51BIwsa0a9euyfsOCRCGSoQvp2H4SEiYr3/962vdPiTu+eefn7z44ovJ8uXL653r0FBj7QsTb4X7mTdvXrMm72jfvn16LkVtsdxwxj9Kl7wujryu/VAPXwbKy/+3bzYMDTvqqKPSGUePPfbYJj9G2jZ5XRx53djw6nAuZjh1AhqS18WR1++++26y5557JjfddFPyta99Lb0uFNZhSHg4/zsMA2/rOV5SBfLahF6gIJyf0NiLpe7McuHLXfgiF07+33bbbdNzJcLtw5j+2v3ENPYCDmI9OQ1Phg/3E/YTXqChd62h0KbmCD1V4ZyK2bNnpy/4tU2HH3qOwhHdcH5FmOo9nKwf3gRuuOGGjXL0J6wJV/vmCPnI68LK64EDBzY66Ud4rGGykdATDvnI68LK67rC+qjhfr/3ve81q0AAeV1YeX3jjTemR+cbrsEc7rt2lKcCuQSMGDEi/dm3b9/oiefhC1w4AT/0XJ1zzjlr9Hw1JQHDDHhBwxP4Z8yY0az2hp6r0KMVeoLWV5iqPSy/EqZ1v+OOO9a63d13353OgheGZtRdmy0kZmMae17eeuutpHPnzus0UULo0QrWdZIFSou8Lqy8rh3mFSb7qCsMxwxD0+Q1TSGvCyuv6woTDYXHang1zSWvCyuv58yZkz6+hp0GtStPrFq1KmnrSuoc5LXZd9990+EbYTa4xpYdCcMQgtpeotpZ8mpdccUVa9ymdo20hgkY7qd3795rTLMeeoKaKszOF9oS3iAatiX8v+5U900Rerquvfba9PyCgw46aK3bhfsMbzh1EybMLBjOTWjM008/Xe+ciDD1/X333Zfss88+jfa4NXy+6wrnZYTnOTx3dc+ngLWR14WV13vssUf65ScMway7dFvoqQ73vffeezfr8VGa5HVh5XVd4QhWOMfRKVA0l7wurLweNWpU+jj+8z//s971tbNth3OT2zpHkP+ZLOGFGc6D22677dKp1UPPShguFCaT2XXXXdPFssN2YVjDxRdfnCbwoEGDkocffjiZNm3aGvusLeLOOuusdH9hCER40YeEDefZXXTRRenPcC5GSNLQo9Ocnqtw/sGPf/zjNDEOOeSQdL240I577703Hd4UJr9pjqOPPjrvNmH6/TCVfRjGEoaDhHM/woQLm2++ebouXUNhUq3wpnfyySenPV21bz7hDSUm7DMke3i+wofthx9+mPzud79L/x5h+E04HxnykdeFlddh20suuSRtU3i+w98l/C3CkhVhghFLwtAU8rqw8rpWWDYm7PeMM85Y65E7WBt5XVh5PWHChHS95XBU+x//+Eey9dZbp4X2ddddl/4ejni3ebkSUHc69ZhJkyalU5iHKeXDNOhh6ZEJEybUmyJ95syZ6fToYTr6sF2Yjn3WrFlrTA0f/PznP88NGjQoV15eXm+q+TBF+8SJE9Pbh6ndw3IIc+fOXev08vPmzWu0vXfffXdu3LhxuaqqqvSy5ZZb5k488cTcm2++2SLPR2PTy19//fW5kSNH5jp06JDeX9hXbTvrCv8PbbnllltWbz9mzJj0Oc7n4Ycfzu299965/v3759q1a5c+1/vss0/usccey3tbSoe8Lq68rrscxzbbbJPetl+/frmTTjop99lnnzX59rRt8ro48/qMM85I9zNlypQm34bSIa+LL69nzpyZO+aYY3LDhg1Ll24LSz6F5bbW9ly0NWXhn9Yu0ml7Qg/yiSeemPb4AW2DvIa2R15D2yOv149zkAEAAECBDAAAABkFMgAAAIQh6s5BBgAAAEeQAQAAIKVABgAAAAUyAAAAZCqTJtq7fHxTNwUiHqm5MykU+3ad0NpNgDbhoYU3JoXEZza0vc9seQ0bJ68dQQYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAQJIklUkbUjloYDT+8W5DovFFA+P9BQOfWBiN5ya/HI0DDQwbnHeTXMf421Tu+VeSYlZeVdXaTQAA4J8cQQYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAABTIAAAAkFEgAwAAQFtbBzlX1Ska73rczGj8jCF/jsYPPm1JND5t5aJo/Mr5e0Tjj38wIhr/eFb3pNhVLKyIxjf986povMODk1u4RbSmd47smXebiuVl0fiQ55OiVrN4cWs3oU2wnnTpKf/ClvH4gs+i8dyKldF49bx569SuUlLWrn00Xr5Jj2i8es7cFm4RwPpzBBkAAAAUyAAAAJBRIAMAAIACGQAAADIKZAAAAFAgAwAAQEaBDAAAAG1tHeTqt96Jb/ClePjqZFSeeNyH/zY2Gh91yFvR+DeGvRCNLxkaX29wZU18jeFgUIeP4/vIxffxwfL4urWdK1ZE40PaL4jGOx4cX5fygh2+EY0P/vlT0TiFZatd3827TWV5dTS+8LwWbBBQMGadFv9M7fJBTTTe/Z5p0Xhu+fJovKJn/PNu6U6bR+PtPot/HlZ+vCTJZ1XPztF4riJ+nGNl1/jXvA4f5XkOFsbj7x3UKxpf/oX4Yxx5Xrckn+o33867DRvHJ0ftknebj7eOx3v/IxeNd3lvaTReOX9hNF49Nf/3CsjHEWQAAABQIAMAAEBGgQwAAAAKZAAAAMgokAEAAECBDAAAABkFMgAAALS1dZBb24D/iK/Bu/A/4rf/c1KVbGh/T+JrFuYXX78uSdpFo88k/aPxWafH171cOnxVnvunmLz01pC823SfEn9N9Uvmt2CLgJZQ3jm+fm9q1GbR8MBL86xrX1YWDedy+T6v4qo//jgar6mM3/9HW8efg56vx28fLBjdKRrP5WnDsjwf+UPOmxyNx1ehT5KyA+Kf2asWx9+/a7p2zHMPFJJeD7+Td5tOR8Vf9713XRSNd6yIf8/71/5/jsZ37Rg/9jdlxbJo/OvPfC8aX/lZh2i8ssvKaDzd5s0mvD9G5Cri723tFsXfFwZenOe9FUeQAQAAIFAgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIWAeZgjLwkvjabNV7brfR2sKGt8Wvl+Tdpmx5fCXOmhZsD42rHDo4Gl814/2N1haKQ82S/LmdvPja+t3Jeq5zvL46PvBcPN4C99HnyaSgrfziwmi855+7ROO5519p4RaxIVXPmZt3m6rjh0bj87caFo13nLM0Gj+rz/HR+MdbxtfeTv4lvr55VacV0fji+N6TnYdOz7NFkszt3zUaX14dL8+mT+0Xja+qynP8c8fPx+PPvZyUOkeQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAABgHWSKTcWkF1q7CbSgsjfyrxeYT3lVVbIhlXXJs/9ePaLh6tfeWr/7b9c+7za5lfF1G/NZdtCO0fion7wajb+303rdPVCgZt69dTRe1X55NN7719ZTLTWrps2Ixjvkiedb3bxDnnj/B/NscHk8XDFqRDRe/fbUaHz+iPg60EF5+/hazZ1WrIzGR02Nr8HO+nMEGQAAABTIAAAAkFEgAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAA1kGm0FRuOigaXzXzg43WFghyixbHN8gT39DrNAdledZUXPovW0Xje53/ZDR+8yO7R+MjkmeicaA4/WbMzdH4sb8/Kc8e1m8deNjYqt96Z/1uP/XdFmsLrccRZAAAAFAgAwAAQEaBDAAAAApkAAAAyCiQAQAAQIEMAAAAGQUyAAAAWAeZQlM9e05rNwGKTtmAvtH4jK/lovFF1R2i8RGnte46xxtjLWkoRdv/oyYaP+Glb0fjQ857qoVbBND6HEEGAAAABTIAAABkFMgAAACgQAYAAICMAhkAAAAUyAAAAJBRIAMAAIB1kCk0uVWrWrsJUHTmj+sfjV+3x2+i8XPOODYa75I8u07tAlpXbuw20fi5fa+Lxv9047gWbhFQ6CoHDYzGV30wK2nrHEEGAAAABTIAAABkFMgAAACgQAYAAICMAhkAAAAUyAAAAJBRIAMAAIACGQAAADKV//wJQAEqa5f/bXrZIZ+s1310ufPZpDWVV1W16v1DW7X4nIXR+JYP/ms0PurKp1q4RUChW/XBrKTUOYIMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAAAokAEAACCjQAYAAADrIAMUthVjRuTd5vujHorGT732+Gh8YLJh1zot69Bhg+4fSlVF717R+PjBL0Tjd/x+vxZuEUDxcwQZAAAAFMgAAACQUSADAACAAhkAAAAyCmQAAABQIAMAAEBGgQwAAADWQQZoXWVDBkbj7x7WLu8+Hpj7hWh84KUbdp3jfMoqfdTAhrDTYx9G41e/tEc0Pvy2Z1q4RQDFzxFkAAAAUCADAABARoEMAAAACmQAAADIKJABAABAgQwAAAAZBTIAAABYBxlgwyrr1DEan/61PtH4l3Z8Ke99vD9uZdKayquqWvX+oa2aeebYaPzQ7pdF45Nu2bWFWwTQ9jmCDAAAAApkAAAAyCiQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAA6yADrKfyeD/jggNGReO9d/swGn/+99vkbULflU/l3QYoLOWjt8y7zUMnXByN73n76dH48P9+utntAih1jiADAACAAhkAAAAyCmQAAABQIAMAAEBGgQwAAAAKZAAAAMgokAEAAMA6yADrp7xH92h8xPFvROM92i+Nxt+5ZlrS2sqrqlq7CdDm/OKBG/Nuc+6s/aLx4f/3mRZsEVAIyjt3jsZrlizZaG0pVY4gAwAAgAIZAAAAMgpkAAAAUCADAABARoEMAAAACmQAAADIKJABAADAOsgbWXlFPF5TvbFaAjRRedcu0fiHBw6Oxo/v+/to/OqRo9apXUBhm/bvu0Tjry2fkXcf7/70c9F4+9zkZrcLaF3lVVXReFm7POWZZZA3OEeQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAABgHeSNzDrHUHQ+22WzaLzP+Pej8VMmfSsaH5VMLvg1GYHme+voa6PxYQ8em3cfo/6n9d8fgJZVs3hxazeBPBxBBgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAAFMgAAACQUSADAACAAhkAAAAylf/8SRGoGbdtNP7xFp3y7qPX9U+3YIug+JUN6BuNf3DIymh8764L4nfwvZlJayuvqmrtJkCbM/uUsdH4yL/EP7M7v92+hVsEQEtwBBkAAAAUyAAAAJBRIAMAAIACGQAAADIKZAAAAFAgAwAAQEaBDAAAANZBLi5L+3WIxpf3LNtobYG2YsEu/aPx3437f9H4Dy8/IRrvmzy1Tu0CWldZZfwr0mdbxddIr/iwYzTeaX5undoFwIblCDIAAAAokAEAACCjQAYAAAAFMgAAAGQUyAAAAKBABgAAgIwCGQAAAKyDXFyq7n42Ht9oLYG2Y+4u1dH4Hp1qovG+V1nnGNqimh23jsZ/sOtj0fiv7983Gu/126fXqV1Qyir69Y3Gy9q3j8ZXvT+zhVtEW+QIMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAoEAGAACAjAIZAAAArIMMlLqKpfF+wlM/3CHPHla1aHuAjaN8262i8U8Hd4rG77xwn2h82K3WOYaWtmrEgGh88GXvROOXbRrPyzH3nBqN93gt/p2h/1/nJ/lUvz417za0LkeQAQAAQIEMAAAAGQUyAAAAKJABAAAgo0AGAAAABTIAAABkFMgAAACQJElZLpfLtXYjAAAAoLU5ggwAAAAKZAAAAMgokAEAAECBDAAAABkFMgAAACiQAQAAIKNABgAAAAUyAAAAZBTIAAAAJCTJ/wdruIwKBXOI+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_feature_maps(model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc457ad1-3240-4ffb-a8f3-98c6554dfce5",
   "metadata": {
    "id": "riu_K1at3z0R"
   },
   "source": [
    "# Part B - Residual models\n",
    "\n",
    "## B.1 - Residual blocks\n",
    "\n",
    "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
    "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8655fc",
   "metadata": {},
   "source": [
    "**Réponse :** C'est l'hyperparamètre h qui est le nombre de canaux de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec298d4-4372-4a1f-be53-a278d051c0f6",
   "metadata": {
    "id": "gkCILVwd3z0R"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, h):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(d, h)\n",
    "        self.fc2 = nn.Linear(h, d)\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x \n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return out + residual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(ConvolutionalResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  \n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        return out + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7d8b5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "block = ConvolutionalResidualBlock(in_channels=8, hidden_channels=4)\n",
    "\n",
    "x = torch.randn(32, 8, 28, 28)\n",
    "out = block(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0097d-269c-40f4-b182-bdc79bd5c512",
   "metadata": {
    "id": "huKWOvVc3z0S"
   },
   "source": [
    "## B.2 - Stacking residual blocks\n",
    "\n",
    "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
    "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa928ef",
   "metadata": {},
   "source": [
    "\n",
    "- Le modèle avec blocs résiduels atteint 98.73% de précision dès la 3ᵉ époque, ce qui dépasse la précision maximale obtenue avec le modèle à deux couches convolutionnelles + linéaire.\n",
    "\n",
    "- Le modèle résiduel atteint un maximum de 99.11% de précision, ce qui surpasse tous les modèles précédents, y compris le modèle plus profond avec 3 couches linéaires (`h = 100`).\n",
    "\n",
    "---\n",
    "\n",
    "- En augmentant le nombre de blocs résiduels :\n",
    "    - La capacité d'apprentissage augmente.\n",
    "    - La précision sur le jeu de test reste stable et élevée.\n",
    "    - Les blocs résiduels permettent d'entraîner des réseaux plus profonds sans dégradation des performances.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d4de4-11e8-490c-8262-064b3e841fa5",
   "metadata": {
    "id": "U4gg9uWg3z0S"
   },
   "outputs": [],
   "source": [
    "class ResidualModel(torch.nn.Module):\n",
    "    def __init__(self, l, h, k=3, out=8):\n",
    "        super(ResidualModel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(1, out, kernel_size=k, padding=k // 2)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ConvolutionalResidualBlock(out, h) for _ in range(l)]\n",
    "        )\n",
    "\n",
    "        self.flatten_dim = out * 14 * 14\n",
    "        self.fc = nn.Linear(self.flatten_dim, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)           \n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)           \n",
    "        x = self.res_blocks(x)     \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4529bf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Accuracy: 93.56%\n",
      "Test Accuracy: 98.14%\n",
      "[Epoch 2] Train Accuracy: 98.15%\n",
      "Test Accuracy: 98.58%\n",
      "[Epoch 3] Train Accuracy: 98.55%\n",
      "Test Accuracy: 98.73%\n",
      "[Epoch 4] Train Accuracy: 98.74%\n",
      "Test Accuracy: 98.39%\n",
      "[Epoch 5] Train Accuracy: 98.97%\n",
      "Test Accuracy: 98.70%\n",
      "[Epoch 6] Train Accuracy: 99.03%\n",
      "Test Accuracy: 98.95%\n",
      "[Epoch 7] Train Accuracy: 99.13%\n",
      "Test Accuracy: 99.11%\n",
      "[Epoch 8] Train Accuracy: 99.22%\n",
      "Test Accuracy: 98.99%\n",
      "[Epoch 9] Train Accuracy: 99.33%\n",
      "Test Accuracy: 98.92%\n",
      "[Epoch 10] Train Accuracy: 99.35%\n",
      "Test Accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "model = ResidualModel(l=4, h=16, out=8)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, _ = train(model, epoch, lambda x: x, optimizer)\n",
    "    test(model, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7d17e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters of MultiLayer: 146490\n",
      "Total number of parameters of ResidualModel: 25082\n"
     ]
    }
   ],
   "source": [
    "total_params_ResMod = sum(p.numel() for p in ResidualModel(l=4, h=16, out=8).parameters())\n",
    "total_params_MultiLay = sum(p.numel() for p in ConvDeepModel(h=100).parameters())\n",
    "\n",
    "print(f\"Total number of parameters of MultiLayer: {total_params_MultiLay}\")\n",
    "print(f\"Total number of parameters of ResidualModel: {total_params_ResMod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49f3a7",
   "metadata": {},
   "source": [
    "**Réponse :** On a bien beaucoup moins de paramètres !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df418703-b1e1-4276-8ba7-dd5622c7b7cd",
   "metadata": {
    "id": "2nes_ZtBoBu0"
   },
   "source": [
    "# Part C - Reimplementing loss functions\n",
    "\n",
    "## C.0 - Combining losses\n",
    "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
    "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
    "\n",
    "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
    "\n",
    "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
    "1. Using `nn.CrossEntropyLoss()`.\n",
    "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
    "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
    "\n",
    "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e1b6c172",
   "metadata": {
    "id": "e1b6c172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with CrossEntropyLoss:           2.997688055038452\n",
      "Loss with NLLLoss + LogSoftmax:       2.997688055038452\n",
      "Loss with NLLLoss + Softmax + log():  2.997688055038452\n"
     ]
    }
   ],
   "source": [
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "torch.manual_seed(0)\n",
    "scores = torch.randn(n_batch, n_classes)  \n",
    "labels = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "# Méthode 1: CrossEntropyLoss\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "loss1 = criterion1(scores, labels)\n",
    "\n",
    "# Méthode 2: NLLLoss + LogSoftmax\n",
    "criterion2 = nn.NLLLoss()\n",
    "log_probs = F.log_softmax(scores, dim=1)\n",
    "loss2 = criterion2(log_probs, labels)\n",
    "\n",
    "# Méthode 3 \n",
    "soft_probs = F.softmax(scores, dim=1)\n",
    "loss3 = criterion2(soft_probs.log(), labels)  \n",
    "\n",
    "print(\"Loss with CrossEntropyLoss:          \", loss1.item())\n",
    "print(\"Loss with NLLLoss + LogSoftmax:      \", loss2.item())\n",
    "print(\"Loss with NLLLoss + Softmax + log(): \", loss3.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3915b8",
   "metadata": {},
   "source": [
    "On obtient bien les même valeurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba900c6-f7b2-4179-a2f1-f1eede4b6697",
   "metadata": {
    "id": "TWKaTBVd5ftN"
   },
   "source": [
    "## C.1 - Re-implementation\n",
    "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "EfA-3-E7qwgF",
   "metadata": {
    "id": "EfA-3-E7qwgF"
   },
   "outputs": [],
   "source": [
    "def ce(logits, targets):\n",
    "    exp_logits = torch.exp(logits)\n",
    "    probs = exp_logits / torch.sum(exp_logits, dim=1, keepdim=True)\n",
    "\n",
    "    target_probs = probs[torch.arange(len(targets)), targets]\n",
    "    log_likelihood = -torch.log(target_probs)\n",
    "\n",
    "    return log_likelihood.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bd2ade8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual CE : 2.884872\n",
      "Official  : 2.884872\n"
     ]
    }
   ],
   "source": [
    "# Exemple de test\n",
    "n_batch = 4\n",
    "n_classes = 10\n",
    "logits = torch.randn(n_batch, n_classes, requires_grad=True)\n",
    "targets = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "# Notre version\n",
    "manual_loss = ce(logits, targets)\n",
    "\n",
    "# Version officielle PyTorch\n",
    "official_loss = nn.CrossEntropyLoss()(logits, targets)\n",
    "\n",
    "print(f\"Manual CE : {manual_loss.item():.6f}\")\n",
    "print(f\"Official  : {official_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc9140",
   "metadata": {},
   "source": [
    "On obtient bien les même valeurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ec13a-330a-4073-99b9-2eb9dd42d1f8",
   "metadata": {
    "id": "OFG0QfKN7WtO"
   },
   "source": [
    "## C.2 - Stability analysis\n",
    "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48fee0",
   "metadata": {},
   "source": [
    "\n",
    "- `nn.CrossEntropyLoss()` et `log_softmax + NLLLoss` sont stables. Elles utilisent les logits et appliquent une fonction log-softmax pour éviter les problèmes d'overflow ou de sous-flux numériques. Cela permet de traiter des logits extrêmes sans erreurs.\n",
    "\n",
    "\n",
    "- `softmax + log + NLLLoss` est instable. La fonction softmax appliquée aux logits peut produire des valeurs exponentielles très grandes ou très petites, ce qui peut conduire à des résultats infiniment grands ou petits lors de l'application de log.\n",
    "\n",
    "\n",
    "- Cela peut poser problème. Les grandes valeurs de logits peuvent entraîner des erreurs numériques (NaN ou inf), ce qui empêche le modèle d'apprendre correctement ou de donner des résultats valides.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "741771f5-864d-446a-b654-3b4f5a2598ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max logit: 305.669677734375\n",
      "Min logit: -248.78030395507812\n",
      "1. nn.CrossEntropyLoss       : 190.090240\n",
      "2. log_softmax + NLLLoss     : 190.090240\n",
      "3. softmax + log + NLLLoss   : 20.723267\n",
      "4. ce() manually implemented : inf\n"
     ]
    }
   ],
   "source": [
    "n_batch = 4\n",
    "n_classes = 10\n",
    "std = 100\n",
    "\n",
    "logits = torch.randn(n_batch, n_classes) * std\n",
    "targets = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "print(\"Max logit:\", logits.max().item())\n",
    "print(\"Min logit:\", logits.min().item())\n",
    "\n",
    "# 1. CrossEntropyLoss (stable)\n",
    "try:\n",
    "    loss1 = nn.CrossEntropyLoss()(logits, targets)\n",
    "    print(f\"1. nn.CrossEntropyLoss       : {loss1.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(\"1. nn.CrossEntropyLoss       : ERROR -\", e)\n",
    "\n",
    "# 2. log_softmax + NLLLoss (stable)\n",
    "try:\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    loss2 = nn.NLLLoss()(log_probs, targets)\n",
    "    print(f\"2. log_softmax + NLLLoss     : {loss2.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(\"2. log_softmax + NLLLoss     : ERROR -\", e)\n",
    "\n",
    "# 3. softmax + log + NLLLoss (instable)\n",
    "try:\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    log_probs_manual = torch.log(probs + 1e-9) \n",
    "    loss3 = nn.NLLLoss()(log_probs_manual, targets)\n",
    "    print(f\"3. softmax + log + NLLLoss   : {loss3.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(\"3. softmax + log + NLLLoss   : ERROR -\", e)\n",
    "\n",
    "# 4. Notre version manuelle avec log-sum-exp\n",
    "def ce(logits, targets):\n",
    "    log_sum_exp = torch.log(torch.sum(torch.exp(logits), dim=1))  \n",
    "    batch_indices = torch.arange(logits.size(0))  \n",
    "    correct_class_scores = logits[batch_indices, targets] \n",
    "    loss = log_sum_exp - correct_class_scores \n",
    "    return loss.mean()\n",
    "\n",
    "try:\n",
    "    loss4 = ce(logits, targets)\n",
    "    print(f\"4. ce() manually implemented : {loss4.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(\"4. ce() manually implemented : ERROR -\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf7c-b21f-4e18-ac53-1a77adbc60bf",
   "metadata": {
    "id": "Y3y4BfwbBIGy"
   },
   "source": [
    "Re-implement a stable version of cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83d00dab-a37e-48da-880f-81f10efdc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_ce(logits, targets):\n",
    "\n",
    "    logits_stable = logits - torch.max(logits, dim=1, keepdim=True)[0]\n",
    "\n",
    "    log_probs = logits_stable - torch.log(torch.sum(torch.exp(logits_stable), dim=1, keepdim=True))\n",
    "    nll = -log_probs[torch.arange(len(targets)), targets]\n",
    "\n",
    "    return nll.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "32273f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable CE     : 150.87271118164062\n",
      "Official CE   : 150.87271118164062\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(4, 10) * 100  # logits extrêmes\n",
    "targets = torch.randint(0, 10, (4,))\n",
    "\n",
    "# Doit être proche de PyTorch officiel\n",
    "print(\"Stable CE     :\", stable_ce(logits, targets).item())\n",
    "print(\"Official CE   :\", nn.CrossEntropyLoss()(logits, targets).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
